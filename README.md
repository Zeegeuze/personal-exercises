# Portfolio
In order to be prepared for a future in DataScience, I decided to start with a portfolio already.
In January 2024 I started a bootcamp with Le Wagon in 'Data Science and AI'.

## Job hunt
### Intro
The first project I'm working on is a fun way to check where to work in the future. 
It's mainly meant as an exercise in Jupyter Notebook, Python and working with online maps.
So don't be surprised if I end up applying for something / wherewhere totally different.

### What I did
I used the following programs: notebook, Python, Matplotlib, Seaborn and Folium.
I scraped, saved as and uploaded CSV, created maps, heatmaps and plots, added non-existing data to a geoframe,
rescaled features, cleaned data and finished with putting the main elements in slides.

### Link
[Notebook: Job hunt](https://github.com/Zeegeuze/personal-exercises/blob/main/.ipynb_checkpoints/job_preparation-checkpoint.ipynb)

## Preparation presentation bootcamp project
### Intro
I'll need to present a project in my bootcamp*, which needs to be presented to the teacher before. This will be the both the preparation for the teacher as well as the preparation for the presentation.

*I followed a bootcamp 'Data Science and AI' at Le Wagon in Brussels from January 15th to March 15th.

### What I did
This was a Google Colab project where I downloaded and displayed a video from YouTube
I downloaded a dataset of videos from Kaggle, unzipped and saved it on Google Drive
I had a look at the data and distribution and made conclusions regarding the project

### Link
[Notebook: Preparation Presentation Bootcamp Project](https://github.com/Zeegeuze/personal-exercises/blob/main/Preparation_presentation_bootcamp_project.ipynb)

## Final project bootcamp
### Intro
This is the final project we did while following our bootcamp "Data Science & AI" at Le Wagon. We created an app to predict crop diseases. This app also has a [frontend](https://github.com/MahautHDL/save_the_crops_front). The frontend itself is not up-and-running anymore.

### What we did
* Data Analysis
* Clean the data
* Data Preprocessing
* Create a model
* Save the model in Tensorboard
* Visualise the results of the model
* Evaluate the model
* Predict with the model
* Put the model online and connect it to the frontend
* Create a frontend [link](https://github.com/MahautHDL/save_the_crops_front)

### What we used
Matplotlib, Numpy, Pandas, Scikit-Learn, Tensorflow, Tensorboard, MLflow, FastAPI, Uvicorn

### Link
* [Code: Save the Crops](https://github.com/Zeegeuze/save_the_crops)
* [Presentation: Save the Crops](https://www.youtube.com/watch?v=KWvrcZ72Myw)
